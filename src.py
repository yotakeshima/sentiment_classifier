import torch
from torch import nn, optim
from typing import List, Dict
import random
import numpy as np
from collections import Counter
import time
import os

print(torch.__version__)
print(torch.cuda.is_available())

seed = 12345
random.seed(seed)
torch.manual_seed(seed)
np.random.seed(seed)

class FeedForwardNeuralNetClassifier(nn.Module):
    """
    The Feed-Forward Neural Net sentiment classifier.
    """
    def __init__(self, vocab_size, emb_dim, n_hidden_units):
        """
        In the __init__ function, you will define modules in FFNN.
        :param vocab_size: size of vocabulary
        :param emb_dim: dimension of the embedding vectors
        :param n_hidden_units: dimension of the hidden units
        """
        super(FeedForwardNeuralNetClassifier, self).__init__()
        self.vocab_size = vocab_size
        self.emb_dim = emb_dim
        self.n_hidden_units = n_hidden_units
       
        # TODO: implement a randomly initialized word embedding matrix using nn.Embedding
        # It should have a size of `(vocab_size x emb_dim)`
        self.word_embeddings = nn.Embedding(vocab_size, emb_dim)

        # TODO: implement the FFNN architecture using nn functions
        self.W = nn.Linear(emb_dim, n_hidden_units)
        self.g = nn.ReLU()
        self.V = nn.Linear(n_hidden_units, 1)
        self.sigmoid = nn.Sigmoid()

        self.loss = nn.BCEWithLogitsLoss()

    def forward(self, batch_inputs: torch.Tensor, batch_lengths: torch.Tensor) -> torch.Tensor:
        """
        The forward function, which defines how FFNN should work when given a batch of inputs and their actual sent lengths (i.e., before PAD)
        :param batch_inputs: a torch.Tensor object of size (n_examples, max_sent_length_in_this_batch), which is the *indexed* inputs
        :param batch_lengths: a torch.Tensor object of size (n_examples), which describes the actual sentence length of each example (i.e., before PAD)
        :return the logits of FFNN (i.e., the unnormalized hidden units before sigmoid) of shape (n_examples)
        """
        
        word_avg = torch.mean(self.word_embeddings(batch_inputs), 1 )
        logits = torch.squeeze(self.V(self.g(self.W(word_avg))))
        return logits
    
    def batch_predict(self, batch_inputs: torch.Tensor, batch_lengths: torch.Tensor) -> List[int]:
        """
        Make predictions for a batch of inputs. This function may directly invoke `forward` (which passes the input through FFNN and returns the output logits)

        :param batch_inputs: a torch.Tensor object of size (n_examples, max_sent_length_in_this_batch), which is the *indexed* inputs
        :param batch_lengths: a torch.Tensor object of size (n_examples), which describes the actual sentence length of each example (i.e., before PAD)
        :return: a list of predicted classes for this batch of data, either 0 for negative class or 1 for positive class
        """
        logits = self.forward(batch_inputs, batch_lengths)
        
        predicted_labels = self.sigmoid(logits)
        predicted_labels = [1 if x >= 0.5 else 0 for x in predicted_labels]
        return predicted_labels
class SentimentExample:
    """
    Data wrapper for a single example for sentiment analysis.

    Attributes:
        words (List[string]): list of words
        label (int): 0 or 1 (0 = negative, 1 = positive)
        word_indices (List[int]): list of word indices in the vocab, which will generated by the `indexing_sentiment_examples` method
    """

    def __init__(self, words, label):
        self.words = words
        self.label = label
        self.word_indices = None # the word indices in vocab

    def __repr__(self):
        return repr(self.words) + "; label=" + repr(self.label)

    def __str__(self):
        return self.__repr__()

class SentimentBatchIterator:
    """
    A batch iterator which will produce the next batch indexed data.

    Attributes:
        data: a list of SentimentExample objects, which is the source data input
        batch_size: an integer number indicating the number of examples in each batch
        PAD_idx: the index of PAD in the vocabulary
        shuffle: whether to shuffle the data (should set to True only for training)
    """
    def __init__(self, data: List[SentimentExample], batch_size: int, PAD_idx: int, shuffle: bool=True):
        self.data = data
        self.batch_size = batch_size
        self.PAD_idx = PAD_idx
        self.shuffle = shuffle
        
        self._indices = None
        self._cur_idx = None
    
    def refresh(self):
        self._indices = list(range(len(self.data)))
        if self.shuffle:
            random.shuffle(self._indices)
        self._cur_idx = 0

    def get_next_batch(self):
        if self._cur_idx < len(self.data): # loop over the dataset
            st_idx = self._cur_idx
            if self._cur_idx + self.batch_size > len(self.data) - 1:
                ed_idx = len(self.data)
            else:
                ed_idx = self._cur_idx + self.batch_size
            self._cur_idx = ed_idx # update
            # retrieve a batch of SentimentExample data
            batch_exs = [self.data[self._indices[_idx]] for _idx in range(st_idx, ed_idx)]

            # TODO: implement the batching process, which returns batch_inputs, batch_lengths, and batch_labels. 
            # Their elements should all have an integer type.
            batch_lengths = [len(words.words) for words in batch_exs]
            max_length = max(batch_lengths)
            batch_inputs = [words.word_indices for words in batch_exs]
            for i in range(len(batch_inputs)):
                pad_needed = max_length - len(batch_inputs[i])
                if len(batch_inputs[i]) < max_length:
                    while(pad_needed > 0):
                        batch_inputs[i] = batch_inputs[i] + [self.PAD_idx]
                        pad_needed -= 1
            batch_labels = [words.label for words in batch_exs]
            return (torch.tensor(batch_inputs), torch.tensor(batch_lengths), torch.tensor(batch_labels))
        else:
            return None
def indexing_sentiment_examples(exs: List[SentimentExample], vocabulary: List[str], UNK_idx: int):
    """
    Indexing words in each SentimentExample based on a given vocabulary. This method will directly modify the `word_indices` attribute of each ex.
    :param exs: a list of SentimentExample objects
    :param vocabulary: the vocabulary, which should be a list of words
    :param UNK_idx: the index of UNK token in the vocabulary
    """
    for ex in exs:
        ex.word_indices = [vocabulary.index(word) if word in vocabulary else UNK_idx for word in ex.words]

def read_sentiment_examples(infile: str) -> List[SentimentExample]:
    """
    Reads sentiment examples in the format [0 or 1]<TAB>[raw sentence]; tokenizes and cleans the sentences and forms
    SentimentExamples. Note that all words have been lowercased.

    :param infile: file to read from
    :return: a list of SentimentExamples parsed from the file
    """
    f = open(infile)
    exs = []
    for line in f:
        if len(line.strip()) > 0:
            line = line.strip()
            fields = line.split("\t")
            if len(fields) != 2:
                fields = line.split()
                label = 0 if "0" in fields[0] else 1
                sent = " ".join(fields[1:])
            else:
                # Slightly more robust to reading bad output than int(fields[0])
                label = 0 if "0" in fields[0] else 1
                sent = fields[1]
            sent = sent.lower() # lowercasing
            tokenized_cleaned_sent = list(filter(lambda x: x != '', sent.rstrip().split(" ")))
            exs.append(SentimentExample(tokenized_cleaned_sent, label))
    f.close()
    return exs


def read_blind_sst_examples(infile: str) -> List[SentimentExample]:
    """
    Reads the blind SST test set, which just consists of unlabeled sentences. Note that all words have been lowercased.
    :param infile: path to the file to read
    :return: list of tokenized sentences (list of list of strings)
    """
    f = open(infile, encoding='utf-8')
    exs = []
    for line in f:
        if len(line.strip()) > 0:
            line = line.strip()
            words = line.lower().split(" ")
            exs.append(SentimentExample(words, label=-1)) # pseudo label -1
    return exs


def write_sentiment_examples(exs: List[SentimentExample], outfile: str):
    """
    Writes sentiment examples to an output file with one example per line, the predicted label followed by the example.
    Note that what gets written out is tokenized.
    :param exs: the list of SentimentExamples to write
    :param outfile: out path
    :return: None
    """
    o = open(outfile, 'w')
    for ex in exs:
        o.write(repr(ex.label) + "\t" + " ".join([word for word in ex.words]) + "\n")
    o.close()


def evaluate(classifier, exs: List[SentimentExample], return_metrics: bool=False):
    """
    Evaluates a given classifier on the given examples
    :param classifier: classifier to evaluate
    :param exs: the list of SentimentExamples to evaluate on
    :param return_metrics: set to True if returning the stats
    :return: None (but prints output)
    """
    all_labels = []
    all_preds = []

    eval_batch_iterator = SentimentBatchIterator(exs, batch_size=32, PAD_idx=0, shuffle=False) # hard-coded batch size and PAD_idx
    eval_batch_iterator.refresh()
    batch_data = eval_batch_iterator.get_next_batch()
    while batch_data is not None:
        batch_inputs, batch_lengths, batch_labels = batch_data
        # project to device
        batch_inputs = batch_inputs.to(device)
        batch_lengths = batch_lengths.to(device)
        all_labels += list(batch_labels)

        preds = classifier.batch_predict(batch_inputs, batch_lengths=batch_lengths)
        all_preds += list(preds)
        batch_data = eval_batch_iterator.get_next_batch()

    if return_metrics:
        acc, prec, rec, f1 = calculate_metrics(all_labels, all_preds)
        return acc, prec, rec, f1
    else:
        calculate_metrics(all_labels, all_preds, print_only=True)

def calculate_metrics(golds: List[int], predictions: List[int], print_only: bool=False):
    """
    Calculate evaluation statistics comparing golds and predictions, each of which is a sequence of 0/1 labels.
    Returns accuracy, precision, recall, and F1.

    :param golds: gold labels
    :param predictions: pred labels
    :param print_only: set to True if printing the stats without returns
    :return: accuracy, precision, recall, and F1 (all floating numbers), or None (when print_only is True)
    """
    num_correct = 0
    num_pos_correct = 0
    num_pred = 0
    num_gold = 0
    num_total = 0
    if len(golds) != len(predictions):
        raise Exception("Mismatched gold/pred lengths: %i / %i" % (len(golds), len(predictions)))
    for idx in range(0, len(golds)):
        gold = golds[idx]
        prediction = predictions[idx]
        if prediction == gold:
            num_correct += 1
        if prediction == 1:
            num_pred += 1
        if gold == 1:
            num_gold += 1
        if prediction == 1 and gold == 1:
            num_pos_correct += 1
        num_total += 1
    acc = float(num_correct) / num_total
    prec = float(num_pos_correct) / num_pred if num_pred > 0 else 0.0
    rec = float(num_pos_correct) / num_gold if num_gold > 0 else 0.0
    f1 = 2 * prec * rec / (prec + rec) if prec > 0 and rec > 0 else 0.0

    print("Accuracy: %i / %i = %f" % (num_correct, num_total, acc))
    print("Precision (fraction of predicted positives that are correct): %i / %i = %f" % (num_pos_correct, num_pred, prec)
          + "; Recall (fraction of true positives predicted correctly): %i / %i = %f" % (num_pos_correct, num_gold, rec)
          + "; F1 (harmonic mean of precision and recall): %f" % f1)

    if not print_only:
        return acc, prec, rec, f1

# Specify the data paths
train_path = "data/train.txt"
dev_path = "data/dev.txt"
blind_test_path = "data/test-blind.txt" # blind test

# Load train, dev, and test exs and index the words.
train_exs = read_sentiment_examples(train_path)
dev_exs = read_sentiment_examples(dev_path)
test_exs_words_only = read_blind_sst_examples(blind_test_path)
print(repr(len(train_exs)) + " / " + repr(len(dev_exs)) + " / " + repr(len(test_exs_words_only)) + " train/dev/test examples")


word_counter = Counter()
for words in train_exs:
    word_counter.update(words.words)
vocab = [word for word, count in word_counter.items() if count > 2]
assert isinstance(vocab, list)

# Now add the special tokens PAD and UNK
vocab = ["PAD", "UNK"] + vocab
PAD_IDX = 0
UNK_IDX = 1
# Show the vocabulary size:
print("Number of words in the vocabulary:", len(vocab))

indexing_sentiment_examples(train_exs, vocabulary=vocab, UNK_idx=UNK_IDX)
indexing_sentiment_examples(dev_exs, vocabulary=vocab, UNK_idx=UNK_IDX)
indexing_sentiment_examples(test_exs_words_only, vocabulary=vocab, UNK_idx=UNK_IDX)


model = FeedForwardNeuralNetClassifier(vocab_size=len(vocab), emb_dim=300, n_hidden_units=300)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = model.to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)

BATCH_SIZE=32
N_EPOCHS=20

# create a batch iterator for the training data
batch_iterator = SentimentBatchIterator(
    train_exs, batch_size=BATCH_SIZE, PAD_idx=PAD_IDX, shuffle=True)

# training
best_epoch = -1
best_acc = -1
start_time = time.time()
for epoch in range(N_EPOCHS):
    print("Epoch %i" % epoch)

    batch_iterator.refresh() # initiate a new iterator for this epoch

    model.train() # turn on the "training mode"
    batch_loss = 0.0
    batch_example_count = 0
    batch_data = batch_iterator.get_next_batch()
    while batch_data is not None:
        batch_inputs, batch_lengths, batch_labels = batch_data
        # project to the device
        batch_inputs = batch_inputs.to(device)
        batch_lengths = batch_lengths.to(device)
        batch_labels = batch_labels.to(device)
        
        # TODO: clean up the gradients for this batch
        model.zero_grad()

        # TODO: call the model and get the loss
        logits = model(batch_inputs, batch_lengths)
        loss = model.loss(logits, batch_labels.float())
        

        # record the loss and number of examples, so we could report some stats
        batch_example_count += len(batch_labels)
        batch_loss += loss.item() * len(batch_labels)

        # TODO: backpropagation using `loss`
        loss.backward()
        optimizer.step()
        

        # get another batch
        batch_data = batch_iterator.get_next_batch()

    print("Avg loss: %.5f" % (batch_loss / batch_example_count))

    # evaluate on dev set
    model.eval() # turn on the "evaluation mode"
    acc, _, _, _ = evaluate(model, dev_exs, return_metrics=True)
    if acc > best_acc:
        best_acc = acc
        best_epoch = epoch
        print("Secure a new best accuracy %.3f in epoch %d!" % (best_acc, best_epoch))
        
        # Save the current best model parameters
        print("Save the best model checkpoint as `best_model.ckpt`!")
        torch.save(model.state_dict(), "best_model.ckpt")
    
    print("Time elapsed: %s" % time.strftime("%Hh%Mm%Ss", time.gmtime(time.time()-start_time)))
    print("-" * 10)

print("End of training! The best accuracy %.3f was obtained in epoch %d." % (best_acc, best_epoch))
# Load back the best checkpoint on dev set
model.load_state_dict(torch.load("best_model.ckpt"))